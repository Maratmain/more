#!/usr/bin/env python3
"""
E2E Scenario Branch Testing
Tests a single scenario branch (3 nodes) locally with full integration.
"""

import os
import sys
import json
import time
import requests
import argparse
from datetime import datetime
from typing import Dict, List, Any, Optional

# Add project root to path
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(project_root)

class ScenarioBranchTester:
    def __init__(self, 
                 dm_url: str = "http://localhost:8004",
                 llm_url: str = "http://localhost:8080",
                 metrics_url: str = "http://localhost:8010"):
        self.dm_url = dm_url
        self.llm_url = llm_url
        self.metrics_url = metrics_url
        self.session_id = f"test_session_{int(time.time())}"
        self.turn_id = 0
        
        # Test scenario data
        self.test_scenarios = {
            "ba_anti_fraud": {
                "role_profile": "ba_anti_fraud",
                "nodes": [
                    {
                        "id": "afr_l1_intro",
                        "category": "AntiFraud_Rules",
                        "order": 1,
                        "weight": 0.4,
                        "question": "–û–ø–∏—à–∏—Ç–µ –æ–ø—ã—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω—Ç–∏—Ñ—Ä–æ–¥-–ø—Ä–∞–≤–∏–ª –∏ —Å–Ω–∏–∂–µ–Ω–∏–µ –ª–æ–∂–Ω–æ–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π.",
                        "success_criteria": ["–ø—Ä–∞–≤–∏–ª–∞", "–º–µ—Ç—Ä–∏–∫–∏", "FPR/TPR", "–∫–µ–π—Å—ã", "–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è"],
                        "followups": ["–ü—Ä–∏–≤–µ–¥–∏—Ç–µ –ø—Ä–∏–º–µ—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–∞–≤–∏–ª–∞ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ü–∏—Ñ—Ä–∞—Ö"],
                        "next_if_fail": "req_l1_core",
                        "next_if_pass": "afr_l2_cases"
                    },
                    {
                        "id": "afr_l2_cases",
                        "category": "AntiFraud_Rules",
                        "order": 2,
                        "weight": 0.6,
                        "question": "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∫–µ–π—Å–∞—Ö –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞, —Å –∫–æ—Ç–æ—Ä—ã–º–∏ –≤—ã —Ä–∞–±–æ—Ç–∞–ª–∏.",
                        "success_criteria": ["–∫–µ–π—Å—ã", "–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ", "–∞–Ω–∞–ª–∏–∑", "—Ä–µ—à–µ–Ω–∏–µ", "—Ä–µ–∑—É–ª—å—Ç–∞—Ç"],
                        "followups": ["–ö–∞–∫ –≤—ã –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏?"],
                        "next_if_fail": "req_l1_core",
                        "next_if_pass": "req_l1_core"
                    },
                    {
                        "id": "req_l1_core",
                        "category": "Requirements_Engineering",
                        "order": 3,
                        "weight": 0.5,
                        "question": "–û–ø–∏—à–∏—Ç–µ –ø—Ä–æ—Ü–µ—Å—Å —Å–±–æ—Ä–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –¥–ª—è –∞–Ω—Ç–∏—Ñ—Ä–æ–¥-—Å–∏—Å—Ç–µ–º.",
                        "success_criteria": ["—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è", "–∞–Ω–∞–ª–∏–∑", "—Å—Ç–µ–π–∫—Ö–æ–ª–¥–µ—Ä—ã", "–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è", "–≤–∞–ª–∏–¥–∞—Ü–∏—è"],
                        "followups": ["–ö–∞–∫ –≤—ã —Ä–∞–±–æ—Ç–∞–ª–∏ —Å –±–∏–∑–Ω–µ—Å-–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏?"],
                        "next_if_fail": "test_l1_basics",
                        "next_if_pass": "test_l1_basics"
                    }
                ]
            },
            "it_dc_ops": {
                "role_profile": "it_dc_ops",
                "nodes": [
                    {
                        "id": "hw_l1_intro",
                        "category": "DC_HW_x86_RAID_BMC",
                        "order": 1,
                        "weight": 0.4,
                        "question": "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –≤–∞—à–µ–º –æ–ø—ã—Ç–µ —Ä–∞–±–æ—Ç—ã —Å —Å–µ—Ä–≤–µ—Ä–Ω—ã–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ–º x86.",
                        "success_criteria": ["x86", "—Å–µ—Ä–≤–µ—Ä—ã", "BIOS", "BMC", "RAID", "–Ω–∞—Å—Ç—Ä–æ–π–∫–∞"],
                        "followups": ["–ö–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ —Å–µ—Ä–≤–µ—Ä–æ–≤ –≤—ã –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–ª–∏?"],
                        "next_if_fail": "net_l1_basics",
                        "next_if_pass": "hw_l2_raid_bmc"
                    },
                    {
                        "id": "hw_l2_raid_bmc",
                        "category": "DC_HW_x86_RAID_BMC",
                        "order": 2,
                        "weight": 0.6,
                        "question": "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –ø–µ—Ä–≤–∏—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–µ BIOS, BMC –∏ RAID-–∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–æ–≤. –ö–∞–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫—Ä–∏—Ç–∏—á–Ω—ã?",
                        "success_criteria": ["BIOS", "BMC", "RAID", "–Ω–∞—Å—Ç—Ä–æ–π–∫–∞", "–ø–∞—Ä–∞–º–µ—Ç—Ä—ã"],
                        "followups": ["–ö–∞–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã –¥–ª—è –Ω–æ–≤—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤?"],
                        "next_if_fail": "hw_l3_incidents",
                        "next_if_pass": "hw_l3_incidents"
                    },
                    {
                        "id": "net_l1_basics",
                        "category": "LAN_SAN_Networking",
                        "order": 3,
                        "weight": 0.5,
                        "question": "–û–ø–∏—à–∏—Ç–µ –≤–∞—à –æ–ø—ã—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–µ—Ç–µ–≤–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –≤ –¶–û–î.",
                        "success_criteria": ["—Å–µ—Ç—å", "LAN", "SAN", "Cisco", "MikroTik", "–Ω–∞—Å—Ç—Ä–æ–π–∫–∞"],
                        "followups": ["–ö–∞–∫–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª—ã –≤—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏?"],
                        "next_if_fail": "inc_l1_basics",
                        "next_if_pass": "inc_l1_basics"
                    }
                ]
            }
        }
    
    def check_service_health(self) -> Dict[str, bool]:
        """Check health of all required services"""
        print("üîç Checking service health...")
        
        health_status = {}
        
        # Check DM service
        try:
            response = requests.get(f"{self.dm_url}/health", timeout=5)
            health_status["dm"] = response.status_code == 200
            if health_status["dm"]:
                print("‚úÖ Dialog Manager: OK")
            else:
                print("‚ùå Dialog Manager: Failed")
        except Exception as e:
            health_status["dm"] = False
            print(f"‚ùå Dialog Manager: Error - {e}")
        
        # Check LLM service
        try:
            response = requests.get(f"{self.llm_url}/health", timeout=5)
            health_status["llm"] = response.status_code == 200
            if health_status["llm"]:
                print("‚úÖ LLM Service: OK")
            else:
                print("‚ùå LLM Service: Failed")
        except Exception as e:
            health_status["llm"] = False
            print(f"‚ùå LLM Service: Error - {e}")
        
        # Check Metrics service
        try:
            response = requests.get(f"{self.metrics_url}/health", timeout=5)
            health_status["metrics"] = response.status_code == 200
            if health_status["metrics"]:
                print("‚úÖ Metrics Service: OK")
            else:
                print("‚ùå Metrics Service: Failed")
        except Exception as e:
            health_status["metrics"] = False
            print(f"‚ùå Metrics Service: Error - {e}")
        
        return health_status
    
    def simulate_candidate_response(self, node: Dict[str, Any], role_profile: str) -> str:
        """Simulate candidate response based on node and role profile"""
        
        # Role-specific response templates
        responses = {
            "ba_anti_fraud": {
                "AntiFraud_Rules": [
                    "–Ø —Ä–∞–±–æ—Ç–∞–ª —Å –∞–Ω—Ç–∏—Ñ—Ä–æ–¥-–ø—Ä–∞–≤–∏–ª–∞–º–∏ 3 –≥–æ–¥–∞. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–ª –º–µ—Ç—Ä–∏–∫–∏ FPR –∏ TPR, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–ª –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –ª–æ–∂–Ω–æ–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π. –£ –Ω–∞—Å –±—ã–ª–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–µ–π—Å–æ–≤ —Å –∫–∞—Ä—Ç–æ—á–Ω—ã–º –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ–º, –∫–æ—Ç–æ—Ä—ã–µ –º—ã —É—Å–ø–µ—à–Ω–æ –≤—ã—è–≤–∏–ª–∏.",
                    "–í –º–æ–µ–π –ø—Ä–∞–∫—Ç–∏–∫–µ –±—ã–ª–æ –º–Ω–æ–≥–æ —Ä–∞–±–æ—Ç—ã —Å –∞–Ω—Ç–∏—Ñ—Ä–æ–¥-—Å–∏—Å—Ç–µ–º–∞–º–∏. –Ø –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–ª –ø—Ä–∞–≤–∏–ª–∞, –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª –º–µ—Ç—Ä–∏–∫–∏ FPR/TPR, —Ä–∞–±–æ—Ç–∞–ª —Å –∫–µ–π—Å–∞–º–∏ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞. –û—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–Ω–∏–∑–∏—Ç—å –ª–æ–∂–Ω–æ–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ 30%.",
                    "–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å –∞–Ω—Ç–∏—Ñ—Ä–æ–¥–æ–º - 2 –≥–æ–¥–∞. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–ª –ø—Ä–∞–≤–∏–ª–∞, —Ä–∞–±–æ—Ç–∞–ª —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏, –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª –∫–µ–π—Å—ã –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞. –ü–æ–Ω–∏–º–∞—é –≤–∞–∂–Ω–æ—Å—Ç—å –±–∞–ª–∞–Ω—Å–∞ –º–µ–∂–¥—É –≤—ã—è–≤–ª–µ–Ω–∏–µ–º –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ –∏ –ª–æ–∂–Ω—ã–º–∏ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è–º–∏."
                ],
                "Requirements_Engineering": [
                    "–°–æ–±–∏—Ä–∞–ª —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –∞–Ω—Ç–∏—Ñ—Ä–æ–¥-—Å–∏—Å—Ç–µ–º, —Ä–∞–±–æ—Ç–∞–ª —Å –±–∏–∑–Ω–µ—Å-–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏, –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª –∏—Ö –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏. –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–ª —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, –ø—Ä–æ–≤–æ–¥–∏–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é —Å –∑–∞–∫–∞–∑—á–∏–∫–∞–º–∏.",
                    "–û–ø—ã—Ç —Å–±–æ—Ä–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π - 3 –≥–æ–¥–∞. –†–∞–±–æ—Ç–∞–ª —Å–æ —Å—Ç–µ–π–∫—Ö–æ–ª–¥–µ—Ä–∞–º–∏, –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å—ã, –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–ª —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è. –ü—Ä–æ–≤–æ–¥–∏–ª –∏–Ω—Ç–µ—Ä–≤—å—é, –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–ª —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏.",
                    "–°–æ–±–∏—Ä–∞–ª —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å–∏—Å—Ç–µ–º, –≤–∫–ª—é—á–∞—è –∞–Ω—Ç–∏—Ñ—Ä–æ–¥. –†–∞–±–æ—Ç–∞–ª —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π, –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –ø—Ä–æ–≤–æ–¥–∏–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π."
                ]
            },
            "it_dc_ops": {
                "DC_HW_x86_RAID_BMC": [
                    "–†–∞–±–æ—Ç–∞–ª —Å —Å–µ—Ä–≤–µ—Ä–Ω—ã–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ–º x86 4 –≥–æ–¥–∞. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–ª BIOS, BMC, RAID-–∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä—ã. –ó–Ω–∞—é –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏, –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.",
                    "–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å x86 —Å–µ—Ä–≤–µ—Ä–∞–º–∏ - 3 –≥–æ–¥–∞. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–ª BIOS, BMC, RAID. –ü–æ–Ω–∏–º–∞—é –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.",
                    "–†–∞–±–æ—Ç–∞–ª —Å —Å–µ—Ä–≤–µ—Ä–Ω—ã–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ–º, –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–ª BIOS, BMC, RAID-–∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä—ã. –ó–Ω–∞—é –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏."
                ],
                "LAN_SAN_Networking": [
                    "–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–ª —Å–µ—Ç–µ–≤–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –≤ –¶–û–î 3 –≥–æ–¥–∞. –†–∞–±–æ—Ç–∞–ª —Å Cisco, MikroTik, –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–ª LAN –∏ SAN —Å–µ—Ç–∏. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø—Ä–æ—Ç–æ–∫–æ–ª—ã, –≤–∫–ª—é—á–∞—è BGP, OSPF.",
                    "–û–ø—ã—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–µ—Ç–µ–π –≤ –¶–û–î - 2 –≥–æ–¥–∞. –†–∞–±–æ—Ç–∞–ª —Å Cisco –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ–º, –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–ª LAN/SAN, –∑–Ω–∞—é –ø—Ä–æ—Ç–æ–∫–æ–ª—ã –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –∏ –∫–æ–º–º—É—Ç–∞—Ü–∏–∏.",
                    "–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–ª —Å–µ—Ç–µ–≤–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ, —Ä–∞–±–æ—Ç–∞–ª —Å LAN –∏ SAN —Å–µ—Ç—è–º–∏. –ó–Ω–∞—é –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ—Ç–æ–∫–æ–ª—ã –∏ –ø—Ä–∏–Ω—Ü–∏–ø—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–µ—Ç–µ–≤–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è."
                ]
            }
        }
        
        # Get appropriate response based on role and category
        role_responses = responses.get(role_profile, {})
        category_responses = role_responses.get(node["category"], [
            f"–£ –º–µ–Ω—è –µ—Å—Ç—å –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å {node['category']}. –ú–æ–≥—É —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω–µ–µ."
        ])
        
        # Return a random response from the category
        import random
        return random.choice(category_responses)
    
    def test_single_node(self, node: Dict[str, Any], role_profile: str, scores: Dict[str, float]) -> Dict[str, Any]:
        """Test a single interview node"""
        self.turn_id += 1
        
        print(f"\nüéØ Testing Node: {node['id']} ({node['category']})")
        print(f"üìù Question: {node['question']}")
        
        # Simulate candidate response
        candidate_response = self.simulate_candidate_response(node, role_profile)
        print(f"üí¨ Candidate: {candidate_response}")
        
        # Prepare DM request
        dm_request = {
            "node": node,
            "transcript": candidate_response,
            "scores": scores,
            "role_profile": role_profile
        }
        
        # Measure DM response time
        start_time = time.time()
        
        try:
            response = requests.post(
                f"{self.dm_url}/reply",
                json=dm_request,
                timeout=30
            )
            
            end_time = time.time()
            dm_latency_ms = (end_time - start_time) * 1000
            
            if response.status_code == 200:
                dm_response = response.json()
                
                print(f"ü§ñ DM Response: {dm_response.get('reply', 'No reply')}")
                print(f"üìä Next Node: {dm_response.get('next_node_id', 'None')}")
                print(f"üìà Score Update: {dm_response.get('scoring_update', {})}")
                print(f"üö© Red Flags: {dm_response.get('red_flags', [])}")
                print(f"‚è±Ô∏è  DM Latency: {dm_latency_ms:.1f}ms")
                
                # Record metrics
                self.record_metrics(dm_latency_ms, dm_response)
                
                return {
                    "success": True,
                    "node_id": node["id"],
                    "dm_response": dm_response,
                    "dm_latency_ms": dm_latency_ms,
                    "candidate_response": candidate_response,
                    "error": None
                }
            else:
                return {
                    "success": False,
                    "node_id": node["id"],
                    "dm_response": None,
                    "dm_latency_ms": dm_latency_ms,
                    "candidate_response": candidate_response,
                    "error": f"HTTP {response.status_code}: {response.text}"
                }
                
        except Exception as e:
            end_time = time.time()
            dm_latency_ms = (end_time - start_time) * 1000
            
            return {
                "success": False,
                "node_id": node["id"],
                "dm_response": None,
                "dm_latency_ms": dm_latency_ms,
                "candidate_response": candidate_response,
                "error": str(e)
            }
    
    def record_metrics(self, dm_latency_ms: float, dm_response: Dict[str, Any]):
        """Record metrics to metrics service"""
        try:
            # Record DM latency
            metrics_request = {
                "service": "dm",
                "latency_ms": dm_latency_ms,
                "session_id": self.session_id,
                "turn_id": str(self.turn_id)
            }
            
            requests.post(
                f"{self.metrics_url}/latency",
                json=metrics_request,
                timeout=5
            )
            
            # Record turn metrics
            turn_request = {
                "session_id": self.session_id,
                "turn_id": str(self.turn_id),
                "total_turn_s": dm_latency_ms / 1000
            }
            
            requests.post(
                f"{self.metrics_url}/turn",
                json=turn_request,
                timeout=5
            )
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Failed to record metrics: {e}")
    
    def test_scenario_branch(self, scenario_name: str) -> Dict[str, Any]:
        """Test a complete scenario branch (3 nodes)"""
        print(f"üöÄ Starting E2E test for scenario: {scenario_name}")
        print("=" * 60)
        
        if scenario_name not in self.test_scenarios:
            raise ValueError(f"Unknown scenario: {scenario_name}")
        
        scenario = self.test_scenarios[scenario_name]
        role_profile = scenario["role_profile"]
        nodes = scenario["nodes"]
        
        print(f"üë§ Role Profile: {role_profile}")
        print(f"üìã Nodes to test: {len(nodes)}")
        print()
        
        # Initialize scores
        scores = {}
        results = []
        total_start_time = time.time()
        
        # Test each node in sequence
        for i, node in enumerate(nodes):
            print(f"üìç Step {i+1}/{len(nodes)}")
            
            result = self.test_single_node(node, role_profile, scores)
            results.append(result)
            
            if not result["success"]:
                print(f"‚ùå Node test failed: {result['error']}")
                break
            
            # Update scores based on DM response
            scoring_update = result["dm_response"].get("scoring_update", {})
            if scoring_update:
                block = scoring_update.get("block")
                score = scoring_update.get("score", 0.0)
                if block:
                    scores[block] = score
            
            # Determine next node
            next_node_id = result["dm_response"].get("next_node_id")
            if next_node_id and i < len(nodes) - 1:
                # Find next node in our test sequence
                next_node = next((n for n in nodes if n["id"] == next_node_id), None)
                if next_node:
                    # Reorder nodes to follow the path
                    nodes = [next_node] + [n for n in nodes if n["id"] != next_node_id]
        
        total_end_time = time.time()
        total_duration_s = total_end_time - total_start_time
        
        # Calculate summary statistics
        successful_tests = [r for r in results if r["success"]]
        total_dm_latency = sum(r["dm_latency_ms"] for r in successful_tests)
        avg_dm_latency = total_dm_latency / len(successful_tests) if successful_tests else 0
        
        summary = {
            "scenario_name": scenario_name,
            "role_profile": role_profile,
            "total_duration_s": total_duration_s,
            "nodes_tested": len(results),
            "successful_tests": len(successful_tests),
            "success_rate": len(successful_tests) / len(results) * 100 if results else 0,
            "avg_dm_latency_ms": avg_dm_latency,
            "total_dm_latency_ms": total_dm_latency,
            "final_scores": scores,
            "results": results
        }
        
        return summary
    
    def print_summary(self, summary: Dict[str, Any]):
        """Print test summary"""
        print("\n" + "=" * 60)
        print("üìä E2E TEST SUMMARY")
        print("=" * 60)
        print(f"üé≠ Scenario: {summary['scenario_name']}")
        print(f"üë§ Role Profile: {summary['role_profile']}")
        print(f"‚è±Ô∏è  Total Duration: {summary['total_duration_s']:.1f}s")
        print(f"üìã Nodes Tested: {summary['nodes_tested']}")
        print(f"‚úÖ Successful Tests: {summary['successful_tests']}")
        print(f"üìà Success Rate: {summary['success_rate']:.1f}%")
        print(f"‚ö° Avg DM Latency: {summary['avg_dm_latency_ms']:.1f}ms")
        print(f"üìä Total DM Latency: {summary['total_dm_latency_ms']:.1f}ms")
        
        print(f"\nüéØ Final Scores:")
        for block, score in summary['final_scores'].items():
            print(f"   {block}: {score:.2f}")
        
        # SLA compliance check
        sla_compliant = summary['avg_dm_latency_ms'] <= 5000  # 5 seconds
        print(f"\nüéØ SLA Compliance: {'‚úÖ' if sla_compliant else '‚ùå'} {'Compliant' if sla_compliant else 'Violated'}")
        
        if not sla_compliant:
            print("üí° Recommendations:")
            print("   - Reduce max_tokens in DM configuration")
            print("   - Enable backchannel for better UX")
            print("   - Consider hardware upgrade")
    
    def save_results(self, summary: Dict[str, Any], output_file: str):
        """Save test results to JSON file"""
        # Add metadata
        summary["test_metadata"] = {
            "timestamp": datetime.now().isoformat(),
            "session_id": self.session_id,
            "dm_url": self.dm_url,
            "llm_url": self.llm_url,
            "metrics_url": self.metrics_url
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ Results saved to: {output_file}")

def main():
    parser = argparse.ArgumentParser(description="E2E Scenario Branch Testing")
    parser.add_argument("--scenario", choices=["ba_anti_fraud", "it_dc_ops"], 
                       default="ba_anti_fraud", help="Scenario to test")
    parser.add_argument("--dm-url", default="http://localhost:8004", help="DM service URL")
    parser.add_argument("--llm-url", default="http://localhost:8080", help="LLM service URL")
    parser.add_argument("--metrics-url", default="http://localhost:8010", help="Metrics service URL")
    parser.add_argument("--output", default="e2e_test_results.json", help="Output JSON file")
    parser.add_argument("--skip-health-check", action="store_true", help="Skip service health check")
    
    args = parser.parse_args()
    
    tester = ScenarioBranchTester(
        dm_url=args.dm_url,
        llm_url=args.llm_url,
        metrics_url=args.metrics_url
    )
    
    try:
        # Check service health
        if not args.skip_health_check:
            health_status = tester.check_service_health()
            if not all(health_status.values()):
                print("\n‚ùå Some services are not healthy. Use --skip-health-check to proceed anyway.")
                sys.exit(1)
            print()
        
        # Run scenario test
        summary = tester.test_scenario_branch(args.scenario)
        
        # Print summary
        tester.print_summary(summary)
        
        # Save results
        tester.save_results(summary, args.output)
        
        # Exit with appropriate code
        if summary['success_rate'] == 100 and summary['avg_dm_latency_ms'] <= 5000:
            print("\nüéâ All tests passed!")
            sys.exit(0)
        else:
            print("\n‚ö†Ô∏è  Some tests failed or SLA violated")
            sys.exit(1)
            
    except Exception as e:
        print(f"\n‚ùå Test failed with error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
